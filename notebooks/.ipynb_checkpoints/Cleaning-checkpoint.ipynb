{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f010671e",
   "metadata": {},
   "source": [
    "## Notebook 2. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce02c0",
   "metadata": {},
   "source": [
    "I already deleted duplicates and have no missing values for the selftext in previous notebook, but additional cleaning needs to be done as well. Later in this notebook, I wanted to compare RogexpTokenizer, Porter Stemmer and WordNetLemmatizer to clean text and see what works best. Some coding decisions were made with Sophie's help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dcc23b",
   "metadata": {},
   "source": [
    "### 1. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d93ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from  nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d96e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_is_blocked</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>...</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>collections</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>MesbaWhamed67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_dzy4gk0i</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>Yourmemoriesonsale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_1xkkexun</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>020Wombat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_b9p6ytvm</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  allow_live_comments              author  \\\n",
       "0            []                False       MesbaWhamed67   \n",
       "1            []                False  Yourmemoriesonsale   \n",
       "2            []                False           020Wombat   \n",
       "\n",
       "  author_flair_css_class author_flair_richtext author_flair_text  \\\n",
       "0                    NaN                    []               NaN   \n",
       "1                    NaN                    []               NaN   \n",
       "2                    NaN                    []               NaN   \n",
       "\n",
       "  author_flair_type author_fullname author_is_blocked  author_patreon_flair  \\\n",
       "0              text     t2_dzy4gk0i             False                 False   \n",
       "1              text     t2_1xkkexun             False                 False   \n",
       "2              text     t2_b9p6ytvm             False                 False   \n",
       "\n",
       "   ...  crosspost_parent_list author_cakeday  author_flair_background_color  \\\n",
       "0  ...                    NaN            NaN                            NaN   \n",
       "1  ...                    NaN            NaN                            NaN   \n",
       "2  ...                    NaN            NaN                            NaN   \n",
       "\n",
       "   author_flair_template_id  author_flair_text_color distinguished  \\\n",
       "0                       NaN                      NaN           NaN   \n",
       "1                       NaN                      NaN           NaN   \n",
       "2                       NaN                      NaN           NaN   \n",
       "\n",
       "  suggested_sort banned_by collections  edited  \n",
       "0            NaN       NaN         NaN     NaN  \n",
       "1            NaN       NaN         NaN     NaN  \n",
       "2            NaN       NaN         NaN     NaN  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "df1 = pd.read_csv('../data/book.csv')\n",
    "df2 = pd.read_csv('../data/parenting.csv')\n",
    "\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff99c27",
   "metadata": {},
   "source": [
    "### 2. Fixing the size of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db7c2eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4256, 83)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of datasets: a - books, b - parenting\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e70f84a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 70)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16a6476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make each columns similar\n",
    "# this code I've used from Sophie's walkthrough lesson\n",
    "\n",
    "df2.drop(set(df2.columns).difference(df1.columns), axis = 1, inplace = True)\n",
    "\n",
    "df1.drop(set(df1.columns).difference(df2.columns), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88461f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4256, 70)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "180db36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 70)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807416bd",
   "metadata": {},
   "source": [
    "### 3. Exploring columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35ee7dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n",
       "       'author_flair_type', 'author_fullname', 'author_is_blocked',\n",
       "       'author_patreon_flair', 'author_premium', 'awarders', 'can_mod_post',\n",
       "       'contest_mode', 'created_utc', 'domain', 'full_link', 'gildings', 'id',\n",
       "       'is_created_from_ads_ui', 'is_crosspostable', 'is_meta',\n",
       "       'is_original_content', 'is_reddit_media_domain', 'is_robot_indexable',\n",
       "       'is_self', 'is_video', 'link_flair_background_color',\n",
       "       'link_flair_richtext', 'link_flair_text_color', 'link_flair_type',\n",
       "       'locked', 'media_only', 'no_follow', 'num_comments', 'num_crossposts',\n",
       "       'over_18', 'parent_whitelist_status', 'permalink', 'pinned', 'pwls',\n",
       "       'removed_by_category', 'retrieved_on', 'score', 'selftext',\n",
       "       'send_replies', 'spoiler', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'subreddit_subscribers', 'subreddit_type', 'thumbnail', 'title',\n",
       "       'total_awards_received', 'treatment_tags', 'upvote_ratio', 'url',\n",
       "       'whitelist_status', 'wls', 'post_hint', 'preview',\n",
       "       'link_flair_css_class', 'link_flair_template_id', 'link_flair_text',\n",
       "       'author_cakeday', 'author_flair_background_color',\n",
       "       'author_flair_template_id', 'author_flair_text_color', 'banned_by'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Books and parenting have similar columns now\n",
    "\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57bf9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of potential columns to use later\n",
    "\n",
    "columns_to_keep=['id','title','selftext']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245a110",
   "metadata": {},
   "source": [
    "### 4. Data dictionary\n",
    "\n",
    "- I decided to create a list of potential columns that are interested to me and could be used later. Idea of building a 'dictionary' came from Sophie's lesson walkthrough\n",
    "\n",
    "Data Element   |\tDescription\n",
    "---------------|-----------------\n",
    "created_uts    |    Date the post was created\n",
    "id             |\tUnique identier of post\n",
    "num_comments   |    Number of comments\n",
    "retriev_on     |    time stemp(time after time posting)\n",
    "title          |\tPost Title\n",
    "selftext       |\tThe text of the post. Not all posts have text. Some- images or videos.\n",
    "subreddit      |\tName of the subreddit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b285b4",
   "metadata": {},
   "source": [
    "### 5. Concatinatig both subreddits to create a new dataframe with columns I want to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba281d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8435, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat subreddits and set new columns\n",
    "\n",
    "df = pd.concat([df1,df2], copy=False)[columns_to_keep]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a47e94",
   "metadata": {},
   "source": [
    "### 6. Check one more time for Duplicates and missing posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f196b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p7e6e5</td>\n",
       "      <td>10 Quotes Of Wisdom By Iconic Author Dr Seuss</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p7dh6q</td>\n",
       "      <td>Free consultation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                          title selftext\n",
       "6  p7e6e5  10 Quotes Of Wisdom By Iconic Author Dr Seuss      NaN\n",
       "6  p7dh6q                              Free consultation      NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicated id's and selftext\n",
    "\n",
    "df[df.duplicated(subset='id')]\n",
    "df[df.duplicated(subset='selftext')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d674df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "\n",
    "df.drop_duplicates(subset=['selftext'], keep = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c681a9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          object\n",
       "title       object\n",
       "selftext    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning data\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b03aa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title       0\n",
       "selftext    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check nulls\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2a770",
   "metadata": {},
   "source": [
    "### 7. Combine title and selftext in one columns text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64c050ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Why do you like James Joyce?  James Joyce from...\n",
       "2    We - Yevgeny Zamyatin Spoilers\\n\\nJust finishe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For later research and convenience, I've decided to combine text and selftext in one column\n",
    "\n",
    "df['text'] = df['title']+' '+df['selftext']\n",
    "df['text'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f47835",
   "metadata": {},
   "source": [
    "### 8. Deleting posts with links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17bd5f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8432, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of my dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8619907f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine posts with links and decide if I want to delete them\n",
    "\n",
    "df[df['text'].str.contains('http')].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ec1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kite.com/python/answers/how-to-use-re.sub()-in-python#:~:text=to%20use%20re.-,sub()%20in%20Python,to%20replace%20substrings%20in%20strings.\n",
    "# https://docs.python.org/3/library/re.html#module-re\n",
    "\n",
    "df['text'] =  df['text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99883b",
   "metadata": {},
   "source": [
    "### 9. Working on text column and cleaning all text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd368ed5",
   "metadata": {},
   "source": [
    "##### - PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf3b86e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whi doe my 13mo wake up so angry? my h goe and get him when he wake up in the middl of the night while i go pee befor i nurs him back to sleep. and lo is constantli sign “more” and “milk” and “mommy” all while tri to launch himself out of h’ arm and scream hi head off. what can h do?? he is worri that he is go to drop lo.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I wanted to test different ways of cleaning data. 1st is using porter stemmer\n",
    "# Here I've used codes from Sophie's lesson\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "df['stemmed_text'] = df.text.apply(lambda x: ' '.join([ps.stem(w) for w in x.split()]))\n",
    "df['stemmed_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ab351",
   "metadata": {},
   "source": [
    "##### - RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7bddcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why does my mo wake up so angry my h goes and gets him when he wakes up in the middle of the night while i go pee before i nurse him back to sleep and lo is constantly signing more and milk and mommy all while trying to launch himself out of h s arms and screaming his head off what can h do he is worried that he is going to drop lo'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd is is create a function 'clean_text' using RegexpTokenizer\n",
    "# For this, I've used some ideas from https://coderoad.ru/42056872/%D0%9A%D0%B0%D0%BA-%D1%83%D0%B4%D0%B0%D0%BB%D0%B8%D1%82%D1%8C-in-strings-%D1%81-%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E-RegexpTokenizer\n",
    "# https://www.programcreek.com/python/?CodeExample=clean+text\n",
    "\n",
    "\n",
    "def clean_text(sen):\n",
    "    post = sen.lower()\n",
    "    tokenizer = RegexpTokenizer('[a-z]+')\n",
    "    clean_post = \" \".join(tokenizer.tokenize(post))\n",
    "    \n",
    "    return clean_post\n",
    "\n",
    "df['text'] = df['text'].map(lambda x: clean_text(x))\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2b894",
   "metadata": {},
   "source": [
    "###### - WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "070106ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'why doe my mo wake up so angry my h go and get him when he wake up in the middle of the night while i go pee before i nurse him back to sleep and lo is constantly signing more and milk and mommy all while trying to launch himself out of h s arm and screaming his head off what can h do he is worried that he is going to drop lo'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some words have similar roots and I wanted to use WordNetLemmatizer to connect them together\n",
    "# Idea for this code came from Sophie's lesson walkthrough\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "df['lem_text'] = df.text.apply(lambda post: ' '.join([lem.lemmatize(word) for word in post.split()]))\n",
    "df['lem_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644cfb64",
   "metadata": {},
   "source": [
    "### 10. Comparing both cleaning methods and lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15e420cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why do you like james joyce james joyce from m...</td>\n",
       "      <td>whi do you like jame joyce? jame joyc from my ...</td>\n",
       "      <td>why do you like james joyce james joyce from m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we yevgeny zamyatin spoilers just finished thi...</td>\n",
       "      <td>we - yevgeni zamyatin spoiler just finish thi ...</td>\n",
       "      <td>we yevgeny zamyatin spoiler just finished this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>books about non gaussian distributions i just ...</td>\n",
       "      <td>book about non-gaussian distribut i just finis...</td>\n",
       "      <td>book about non gaussian distribution i just fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "1  why do you like james joyce james joyce from m...   \n",
       "2  we yevgeny zamyatin spoilers just finished thi...   \n",
       "3  books about non gaussian distributions i just ...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "1  whi do you like jame joyce? jame joyc from my ...   \n",
       "2  we - yevgeni zamyatin spoiler just finish thi ...   \n",
       "3  book about non-gaussian distribut i just finis...   \n",
       "\n",
       "                                            lem_text  \n",
       "1  why do you like james joyce james joyce from m...  \n",
       "2  we yevgeny zamyatin spoiler just finished this...  \n",
       "3  book about non gaussian distribution i just fi...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare both cleaning methods and lemmatizer\n",
    "\n",
    "df[['text','stemmed_text', 'lem_text']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850d685",
   "metadata": {},
   "source": [
    " - After my exploration, both methods did a great job. But, I like the refexptokenizer more because it doesn's change a root of my words and would delete '/' ';' ':' and other sighns attached to words. The lemmatizer is good too, but I didn't like it would cut smaller words too much that it is hard to understand which word is which. Here is my placements:\n",
    " 1. RogexpTokenizer\n",
    " 2. WordNetLemmatizer\n",
    " 3. Porter Stemmer\n",
    " \n",
    " ### RogexpTokenizer won!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2278a",
   "metadata": {},
   "source": [
    "### 11. Reseting index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b8c2719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1629379545</td>\n",
       "      <td>p7esvi</td>\n",
       "      <td>1629379556</td>\n",
       "      <td>Why do you like James Joyce?</td>\n",
       "      <td>James Joyce from my very brief reading of him...</td>\n",
       "      <td>books</td>\n",
       "      <td>why do you like james joyce james joyce from m...</td>\n",
       "      <td>whi do you like jame joyce? jame joyc from my ...</td>\n",
       "      <td>why do you like james joyce james joyce from m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_utc      id  retrieved_on                         title  \\\n",
       "0   1629379545  p7esvi    1629379556  Why do you like James Joyce?   \n",
       "\n",
       "                                            selftext subreddit  \\\n",
       "0   James Joyce from my very brief reading of him...     books   \n",
       "\n",
       "                                                text  \\\n",
       "0  why do you like james joyce james joyce from m...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  whi do you like jame joyce? jame joyc from my ...   \n",
       "\n",
       "                                            lem_text  \n",
       "0  why do you like james joyce james joyce from m...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index reset\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396504db",
   "metadata": {},
   "source": [
    "### 12. Final Columns to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f794237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After some thoughts, I decided to keep only 2 columns 'subreddit' and 'text'\n",
    "\n",
    "cols = ['subreddit','text']\n",
    "new_df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72dd3a",
   "metadata": {},
   "source": [
    "### 13. Convert column subreddit to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ea38d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My goal is to preddict if words come from subreddit 'books'. \n",
    "#That's why I'm converting books to nummerical.  books would be - 1 and parenting would be 0\n",
    "\n",
    "new_df = pd.get_dummies(new_df, columns = ['subreddit'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a2a77",
   "metadata": {},
   "source": [
    "### 14. Created a new dataframe 'cleaned.csv' what is ready for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "260caad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a new dataframe\n",
    "\n",
    "new_df.to_csv('../data/cleaned_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e183a",
   "metadata": {},
   "source": [
    "######  Proceed to next notebook EDA!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
