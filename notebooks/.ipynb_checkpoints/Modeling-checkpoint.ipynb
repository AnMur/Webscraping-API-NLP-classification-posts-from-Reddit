{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053b155e",
   "metadata": {},
   "source": [
    "## Vectorizing and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a627b",
   "metadata": {},
   "source": [
    "### 1. Loading info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ff493",
   "metadata": {},
   "source": [
    "- In this notebook, I wanted to test 4 different models: Logistic Regression, KNN, Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a73301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's import libraries and modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "537aac1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit_Parenting</th>\n",
       "      <th>subreddit_books</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why do you like james joyce james joyce from m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we yevgeny zamyatin spoilers just finished thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  subreddit_Parenting  \\\n",
       "0  why do you like james joyce james joyce from m...                    0   \n",
       "1  we yevgeny zamyatin spoilers just finished thi...                    0   \n",
       "\n",
       "   subreddit_books  \n",
       "0                1  \n",
       "1                1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataset\n",
    "\n",
    "df = pd.read_csv('../data/cleaned_df.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d505c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'me', 'my', 'myself', 'we'], dtype='<U10')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recover stop words\n",
    "%store -r sw\n",
    "\n",
    "np.array(sw)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb0cb0",
   "metadata": {},
   "source": [
    "### 2. Evaluating a Baseline score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653bfd8d",
   "metadata": {},
   "source": [
    "- My baseline is 0.5. Words from both subreddits are equally distributed. But, we will see if any of our 4 models could predict words from the book's subreddit and receive a score more than %50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ceecaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.504507\n",
       "0    0.495493\n",
       "Name: subreddit_books, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit_books'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa4b1f",
   "metadata": {},
   "source": [
    "### 3. Establishing target, features, train, test and split our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ff21c",
   "metadata": {},
   "source": [
    "- My target is to predict words that belong to subreddit books\n",
    "- My features would be text\n",
    "- Also,I need to split text in my dataset to train and test samples. By default, the train-test-split would split my model to 4 different parts, I wanted to split it to 5 parts that's why I'm using test_size 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8131a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X,y and train-test-split\n",
    "\n",
    "X = df.text\n",
    "y = df.subreddit_books\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                           random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337afa5",
   "metadata": {},
   "source": [
    "### 4. Instantiating the Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c433af92",
   "metadata": {},
   "source": [
    " - In this notebook, I wanted to compare both Count Vectorizer and Tf-Idf Vectorizer to check which one would perform better for my models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78a32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize words \n",
    "\n",
    "cvec = CountVectorizer(strip_accents = 'ascii',\n",
    "                       stop_words = sw)\n",
    "\n",
    "#vec fit transform \n",
    "vect_cvec =pd.DataFrame(cvec.fit_transform(df.text).todense(), \n",
    "                        columns=cvec.get_feature_names())\n",
    "\n",
    "X_cvec = vect_cvec\n",
    "\n",
    "\n",
    "X_train_cvec = cvec.fit_transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)\n",
    "\n",
    "# X = StandardScaler().fit_transform(vect_cvec) I used scaling as well in experiments on some models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9485c94",
   "metadata": {},
   "source": [
    "### 5. Instantiating the Tf-Idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "282e1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfIdf Vectorizer\n",
    "\n",
    "tfidf =TfidfVectorizer(strip_accents = 'ascii',\n",
    "                       stop_words = sw)           \n",
    "\n",
    "vect_tf = pd.DataFrame(tfidf.fit_transform(df.text).todense(),\n",
    "                       columns = tfidf.get_feature_names())\n",
    "\n",
    "Xtf = vect_tf\n",
    "\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)\n",
    "   \n",
    "# Xtf_sc = StandardScaler().fit_transform(Xtf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35915a62",
   "metadata": {},
   "source": [
    "### 6. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a76206f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9936249073387695\n",
      "test: 0.98814463544754\n",
      "cross val logs: 0.988 ± 0.004\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the Logistic Regression with tf-idf vectorizer. Cross val score is performed on entire dataset using KFold\n",
    "\n",
    "logs = LogisticRegression(n_jobs = -1)\n",
    "\n",
    "logs.fit(X_train_tf, y_train)\n",
    "\n",
    "\n",
    "logs_score = cross_val_score(logs, Xtf, y, cv = KFold(n_splits=5,\n",
    "                                                         shuffle = True,\n",
    "                                                         random_state = 42) )\n",
    "\n",
    "print('train:', logs.score(X_train_tf, y_train))\n",
    "print('test:', logs.score(X_test_tf, y_test))\n",
    "print('cross val logs:', round(logs_score.mean(), 3), '±', round(2*logs_score.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a1792",
   "metadata": {},
   "source": [
    "### 7. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9345100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Standard Scaler, fit and transfer it on the entire tfidf's text\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "Xtf_sc = StandardScaler().fit_transform(Xtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f10ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cros val rf: 0.539 ± 0.077\n"
     ]
    }
   ],
   "source": [
    "# KNN. I've got all score for KNN before. But, it takes very long time to run all and I've decided to get only cross_val_score for KNN this time.\n",
    "# This model I'm using only for experimentations\n",
    "\n",
    "knn = KNeighborsClassifier(n_jobs=-1,\n",
    "                           p=2, # defines minkowski distance: euclidean\n",
    "                           weights='distance',\n",
    "                           n_neighbors=7)\n",
    "\n",
    "knn_score = cross_val_score(knn, Xtf_sc, y, cv = KFold(n_splits=5,\n",
    "                                                       shuffle = True,\n",
    "                                                       random_state = 42))\n",
    "\n",
    "print('cros val rf:', round(knn_score.mean(), 3), '±' , round(2*knn_score.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567494f",
   "metadata": {},
   "source": [
    "### 8. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "035c5733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9369903632320237\n",
      "Score on testing set: 0.9270895080023711\n",
      "cros val rf: 0.983 ± 0.006\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model with:\n",
    "# - a maximum depth of 5.\n",
    "# - at least 7 samples required in order to split an internal node. default 2\n",
    "# - at least 3 samples in each leaf node. default 1\n",
    "# - a cost complexity of 0.01. if it increase, we regularize more. default 0\n",
    "# - random state of 42.\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5,\n",
    "                            min_samples_split=7,\n",
    "                            min_samples_leaf=3,\n",
    "                            ccp_alpha=.01,\n",
    "                            random_state=42)\n",
    "\n",
    "dt.fit(X_train_tf, y_train)\n",
    "\n",
    "dt_score = cross_val_score(dt, Xtf, y, cv = KFold(n_splits=5,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 42))\n",
    "\n",
    "\n",
    "print(f'Score on training set: {dt.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {dt.score(X_test_tf, y_test)}')\n",
    "print('cros val rf:', round(rf_score.mean(), 3), '±' ,  round(2*rf_score.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e7dcc",
   "metadata": {},
   "source": [
    "### 9. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8b5b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.9982209043736101\n",
      "test: 0.9590989922940131\n",
      "cros val rf: 0.956 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, n_jobs = -1)\n",
    "\n",
    "rf.fit(X_train_tf, y_train)\n",
    "\n",
    "\n",
    "rf_score = cross_val_score(rf, Xtf, y, cv = KFold(n_splits=5,\n",
    "                                                     shuffle = True,\n",
    "                                                     random_state = 42))\n",
    "\n",
    "print('train:', rf.score(X_train_tf, y_train))\n",
    "print('test:',  rf.score(X_test_tf, y_test))\n",
    "print('cros val rf:', round(rf_score.mean(), 3), '±' , round(2*rf_score.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60180c17",
   "metadata": {},
   "source": [
    "### 10. Conclusions after initial modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde538e4",
   "metadata": {},
   "source": [
    "After experimenting with different models and combinations, I made next conclusions:\n",
    "\n",
    "- all models would succesfully predict the subreddit and beat the baseline score.\n",
    "\n",
    "- TfIdf Vectorizer performed slightly better than Count Vectorizer by %1. But, Count Vectorizer run slightly faster\n",
    "\n",
    "- KNN with Standard Scaler performed worse than other models. But, probably more custom setting need to be done to this model such as number of neighbors or changing the distance to manhattan for example\n",
    "\n",
    "- I experimented with the Decision Tree and I'm going to leave this model for now because it has lower scores. It is definitely very interesting model with a lot of great parameters what could be used to improve the model\n",
    "\n",
    "- Logistic Regression worked well and would be a good candiate for the winning model. I used it both with the Count Vectoriser and Tf-idf Vectorizer and Logs + tf-idf give the best results. The score is pretty high.\n",
    "\n",
    "- Random Forest is very interesting, it has higher traing score compare to testing and stdiv is 0.01. It has slightly higher variannce and I wanted to use this model in my next notebook to see if I could imprpove the score by changing some parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961fedb",
   "metadata": {},
   "source": [
    "**Proceed to the next notebook!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
